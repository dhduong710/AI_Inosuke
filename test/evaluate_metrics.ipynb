{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "329c3b63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Evaluating Inosuke model ===\n",
      "\n",
      "Q: Xin chào\n",
      "GT: Chào! Ta là Inosuke, kẻ mạnh nhất!\n",
      "PR: Hehe, ta là Inosuke! Đừng sợ hãi với sức mạnh của ta! Ta sẽ bảo vệ ngươi hết cả đời! Hahahaha!\n",
      "[sim=0.670]\n",
      "--------------------------------------------------\n",
      "Q: Ngươi biết Tanjiro không?\n",
      "GT: Hắn mạnh mẽ nhưng quá hiền lành! Ta sẽ đấu với hắn một ngày nào đó!\n",
      "PR: Thằng đó hay la hét, nhưng ta thấy nó mạnh mẽ! Ta sẽ học từ nó.\n",
      "[sim=0.752]\n",
      "--------------------------------------------------\n",
      "Q: Nếu có kẻ yếu hơn ngươi thì ngươi làm gì?\n",
      "GT: Ta sẽ thử đấu! Nếu thắng thì vui, nếu thua thì đánh lại cho đến khi thắng!\n",
      "PR: Ta sẽ hét vào mặt hắn, rồi xé toạc hắn ra để chứng minh sức mạnh thật sự!\n",
      "[sim=0.646]\n",
      "--------------------------------------------------\n",
      "Q: Miêu tả cảm giác khi chiến thắng.\n",
      "GT: Giống như lửa trong người bùng cháy! Vết thương không còn quan trọng, chỉ còn niềm vui hét thật to!\n",
      "PR: Ngươi đã đánh bại ta, nhưng ta vẫn là kẻ mạnh nhất! Ta sẽ chứng minh điều đó cho ngươi thấy.\n",
      "[sim=0.610]\n",
      "--------------------------------------------------\n",
      "Q: Ngươi thích ăn gì nhất?\n",
      "GT: Thịt nướng! Nướng cháy cạnh mới ngon!\n",
      "PR: Nếu phải chọn, thì cơm trắng và thịt nướng! Ngực ta rung lên khi nghĩ đến mùi thơm ấy.\n",
      "[sim=0.592]\n",
      "--------------------------------------------------\n",
      "\n",
      "=== Results ===\n",
      "BLEU: 0.0000\n",
      "ROUGE-L: 0.3281\n",
      "Embedding similarity: 0.6541\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import torch\n",
    "import evaluate\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "from peft import PeftModel\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "# Config \n",
    "BASE_MODEL = r\"D:\\AI-Inosuke\\models\\Qwen2.5-3B-Instruct\"\n",
    "LORA_ADAPTER = r\"D:\\AI-Inosuke\\models\\inosuke-lora\\checkpoint-2605\"\n",
    "TEST_FILE = r\"D:\\AI-Inosuke\\test\\test_set.jsonl\"\n",
    "\n",
    "# Load tokenizer + model\n",
    "tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL)\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    ")\n",
    "\n",
    "print(\"Loading model...\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    BASE_MODEL,\n",
    "    device_map=\"auto\",\n",
    "    quantization_config=bnb_config,\n",
    "    torch_dtype=torch.float16,\n",
    ")\n",
    "model = PeftModel.from_pretrained(model, LORA_ADAPTER)\n",
    "\n",
    "# Load metrics\n",
    "bleu = evaluate.load(\"bleu\")\n",
    "rouge = evaluate.load(\"rouge\")\n",
    "embedder = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# Helper\n",
    "def generate_response(prompt, max_new_tokens=150):\n",
    "    text = f\"### Instruction:\\n{prompt}\\n\\n### Response:\\n\"\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\").to(model.device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            do_sample=True,\n",
    "            temperature=0.35,\n",
    "            top_p=0.85,\n",
    "            repetition_penalty=1.15\n",
    "        )\n",
    "    decoded = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    if \"### Response:\" in decoded:\n",
    "        return decoded.split(\"### Response:\")[-1].strip()\n",
    "    return decoded.strip()\n",
    "\n",
    "# Load test set \n",
    "with open(TEST_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "    test_data = [json.loads(line) for line in f if line.strip()]\n",
    "\n",
    "# Evaluation \n",
    "all_preds, all_refs = [], []\n",
    "similarities = []\n",
    "\n",
    "print(\"\\n=== Evaluating Inosuke model ===\\n\")\n",
    "\n",
    "for ex in test_data:\n",
    "    instr, expected = ex[\"instruction\"], ex[\"expected\"]\n",
    "    pred = generate_response(instr)\n",
    "\n",
    "    all_preds.append(pred)\n",
    "    all_refs.append(expected)\n",
    "\n",
    "    # Embedding similarity\n",
    "    emb1, emb2 = embedder.encode(pred, convert_to_tensor=True), embedder.encode(expected, convert_to_tensor=True)\n",
    "    sim = util.cos_sim(emb1, emb2).item()\n",
    "    similarities.append(sim)\n",
    "\n",
    "    print(f\"Q: {instr}\")\n",
    "    print(f\"GT: {expected}\")\n",
    "    print(f\"PR: {pred}\")\n",
    "    print(f\"[sim={sim:.3f}]\")\n",
    "    print(\"-\"*50)\n",
    "\n",
    "# Metrics \n",
    "bleu_score = bleu.compute(predictions=all_preds, references=[[r] for r in all_refs])\n",
    "rouge_score = rouge.compute(predictions=all_preds, references=all_refs)\n",
    "avg_sim = np.mean(similarities)\n",
    "\n",
    "print(\"\\n=== Results ===\")\n",
    "print(f\"BLEU: {bleu_score['bleu']:.4f}\")\n",
    "print(f\"ROUGE-L: {rouge_score['rougeL']:.4f}\")\n",
    "print(f\"Embedding similarity: {avg_sim:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "inosuke2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
